"""
Library of functions that compute the topic coverage scores of a model-generated summary when compared
to topic coverage of the manually generated summaries of the validation set. 
"""


from modeling.lda import *
from gensim.models import LdaModel
import pickle
import os
from sklearn import metrics
import seaborn as sns
import matplotlib.pyplot as plt

VALIDATION_SET_PATH = "resources/validation_set"


class TopicCoverageValidation:

    def __init__(self):

        with open("resources/ALL_TEXT.txt", 'r', encoding='utf-8') as f:
            text = f.read().splitlines()
        all_tokens = list()
        for line in text:
            all_tokens.append(prepare_text_for_lda(line))

        self.dictionary = corpora.Dictionary(all_tokens)
        self.NUM_TOPICS = 15
        self.ldamodel = LdaModel.load('modeling/alltext15.gensim')



    def get_manual_topic_vectors(self):
        """
        Obtains the topic vectors from the manual summmaries of the validation files
        :return: a list of topic vectors for the validation files
        """

        best_topics = list()
        for root, dirs, files in os.walk(VALIDATION_SET_PATH):
            for file in files:
                doc_topics = np.zeros(15)
                with open(os.path.join(VALIDATION_SET_PATH, file), 'r', encoding='utf-8') as f:
                    validation_doc = f.read().splitlines()
                for line in validation_doc:
                    new_doc = prepare_text_for_lda(line)
                    new_doc_bow = self.dictionary.doc2bow(new_doc)
                    tmax = np.argmax([two for one, two in self.ldamodel.get_document_topics(new_doc_bow)])
                    sent_topic = self.ldamodel.get_document_topics(new_doc_bow)[tmax][0]
                    doc_topics[sent_topic] += 1
                print(doc_topics)
                doc_topics = doc_topics / np.linalg.norm(doc_topics)
                best_topics.append(doc_topics)
        return best_topics


    def compute_topic_scores(self, doc_sents):
        """
        Computes a topic specifying how the sentences fall into the 15 topics
        :param doc_sents: sentences of the document
        :param dictionary:
        :param ldamodel:
        :return: the length 15 topic vector
        """
        doc_topics = np.zeros(15)

        for line in doc_sents:
            new_doc = prepare_text_for_lda(line)
            new_doc_bow = self.dictionary.doc2bow(new_doc)
            tmax = np.argmax([two for one, two in self.ldamodel.get_document_topics(new_doc_bow)])
            sent_topic = self.ldamodel.get_document_topics(new_doc_bow)[tmax][0]
            doc_topics[sent_topic] += 1
        doc_topics = doc_topics / np.linalg.norm(doc_topics)
        return doc_topics


    # def plot_topic_vecs(self):
        
    #     # run if the autogen_topics.pkl file does not exist in the current directory (or if it needs to be regenerated)
    #     # output = open('modeling/autogen_topics.pkl', 'wb')
    #     # pickle.dump(topic_results, output)
    #     # output.close()
    #     best_topics = self.get_manual_topic_vectors()

    #     # load the topic vectors for the autogenerated summaries 
    #     pkl_file = open('modeling/autogen_topics.pkl', 'rb')
    #     topic_results = pickle.load(pkl_file)
    #     pkl_file.close()

    #     autogen_topics = list()
    #     for root, dirs, files in os.walk(VALIDATION_SET_PATH):
    #         for file in files:
    #             autogen_topics.append(topic_results[file]['lda'])

    #     print(autogen_topics)
    #     cosine = metrics.pairwise.cosine_similarity(autogen_topics, best_topics)
    #     sns.heatmap(cosine, cmap="YlGnBu")
    #     plt.show()






