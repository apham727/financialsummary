{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md \n"
    }
   },
   "source": [
    "Attempting to Determine a Threshold for Similarity between 10Qs and a sample legal document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b327f60a77e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegal_filter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfile_to_sents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_legal_bank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'preprocessing'"
     ]
    }
   ],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from nltk import tokenize\n",
    "import seaborn\n",
    "from sklearn import metrics\n",
    "from preprocessing.legal_filter import file_to_sents, get_legal_bank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Universal Sentence Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logging.set_verbosity(logging.ERROR)\n",
    "legal_vectors = model(get_legal_bank())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# get the sections associates with one particular 10Q\n",
    "company_code = \"ORCL\"\n",
    "release_date = \"20180831\"\n",
    "comp_dir = os.path.join(os.path.expanduser(\"resources/itemized\"), company_code)\n",
    "\n",
    "sections = {}\n",
    "for root, dirs, files in os.walk(comp_dir):\n",
    "    for file in files: \n",
    "        if release_date in file:\n",
    "            # get the section identifier (i.e. part2, item1, etc)\n",
    "            identifier = file.split(\"_\")[3].replace(\".txt\", \"\")\n",
    "            \n",
    "            sections[identifier] = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_sents = 0\n",
    "sect_score_maxes = {}\n",
    "for sect_id, sect in sections.items():\n",
    "    sents = file_to_sents(os.path.join(comp_dir, sect))\n",
    "    if not len(sents) > 0: \n",
    "        continue\n",
    "    doc_vectors = model(sents)\n",
    "    total_sents += len(doc_vectors)\n",
    "    cosine = metrics.pairwise.cosine_similarity(doc_vectors, legal_vectors)    \n",
    "    score_maxes = np.amax(cosine, axis=1)\n",
    "    sect_score_maxes[sect_id] = score_maxes\n",
    "total_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## plot histogram \n",
    "\n",
    "def by_value(item):\n",
    "    # for iterating by sorted value (from largest to smallest) to make larger histograms plot behind smaller ones\n",
    "    return -1 * len(item[1])\n",
    "\n",
    "\n",
    "for sect_id, score_maxes in sorted(sect_score_maxes.items(), key=by_value):\n",
    "    if len(score_maxes) < 10: \n",
    "        print(\"continued\")\n",
    "        continue\n",
    "    plt.hist(score_maxes, label = sect_id, alpha = 0.7)\n",
    "#     plt.axvline(np.median(score_maxes), color = 'r', label= (sect_id + \" mean\"))\n",
    "#     plt.axvline(np.mean(score_maxes), color = 'g')\n",
    "plt.xticks(np.arange(0.0, 0.9, 0.1))\n",
    "plt.title(\"Maximum Cosine Similarity Between Legal Bank and \" + company_code + \" Sentences\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib ipympl\n",
    "\n",
    "sns.heatmap(cosine,cmap=\"YlGnBu\")\n",
    "\n",
    "plt.title(\"Cosine Similarity Heatmap between Apple 10Q and Set of Cautionary Statements\")\n",
    "plt.ylabel(\"2018 Apple 10Q\")\n",
    "plt.xlabel(\"Set of Forward Looking Statments\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "thresh = 0.9\n",
    "idcs = np.where(np.logical_and(cosine > 0.28, cosine < 0.3))\n",
    "np.shape(idcs)\n",
    "idcs\n",
    "# print(non_empty[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(non_empty[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
