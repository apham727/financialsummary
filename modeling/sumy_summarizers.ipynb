{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "sumy_summarizers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "wJedZzCYnioJ",
    "colab_type": "code",
    "outputId": "20e497d5-ac08-40a2-c689-c272d408285c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "import nltk\n",
    "import os\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.edmundson import EdmundsonSummarizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.summarizers.sum_basic import SumBasicSummarizer\n",
    "from sumy.summarizers.kl import KLSummarizer\n",
    "from sumy.summarizers.reduction import ReductionSummarizer\n",
    "\n",
    "from modeling.run_model import summarize_company_docs"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lToSmzV-nI62",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "def LexRankSummary(document, sentences):\n",
    "    parser = PlaintextParser.from_string(document,Tokenizer(\"english\"))\n",
    "    summarizer = LexRankSummarizer()\n",
    "    summary = summarizer(parser.document, sentences)\n",
    "    results = []\n",
    "    for sentence in summary:\n",
    "        results.append(str(sentence))\n",
    "    return results\n",
    "\n",
    "def LuhnSummary(document, sentences):\n",
    "    parser = PlaintextParser.from_string(document,Tokenizer(\"english\"))\n",
    "    summarizer = LuhnSummarizer()\n",
    "    summary = summarizer(parser.document, sentences)\n",
    "    results = []\n",
    "    for sentence in summary:\n",
    "        results.append(str(sentence))\n",
    "    return results\n",
    "\n",
    "def LsaSummary(document, sentences):\n",
    "    parser = PlaintextParser.from_string(document,Tokenizer(\"english\"))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, sentences)\n",
    "    results = []\n",
    "    for sentence in summary:\n",
    "        results.append(str(sentence))\n",
    "    return results\n",
    "\n",
    "def EdmundsonSummary(document, sentences):\n",
    "    parser = PlaintextParser.from_string(document,Tokenizer(\"english\"))\n",
    "    summarizer = EdmundsonSummarizer()\n",
    "    summary = summarizer(parser.document, sentences)\n",
    "    results = []\n",
    "    for sentence in summary:\n",
    "        results.append(str(sentence))\n",
    "    return results\n",
    "\n",
    "def TextRankSummary(document, sentences):\n",
    "    parser = PlaintextParser.from_string(document,Tokenizer(\"english\"))\n",
    "    summarizer = TextRankSummarizer()\n",
    "    summary = summarizer(parser.document, sentences)\n",
    "    results = []\n",
    "    for sentence in summary:\n",
    "        results.append(str(sentence))\n",
    "    return results\n",
    "\n",
    "def SumBasicSummary(document, sentences):\n",
    "    parser = PlaintextParser.from_string(document,Tokenizer(\"english\"))\n",
    "    summarizer = SumBasicSummarizer()\n",
    "    summary = summarizer(parser.document, sentences)\n",
    "    results = []\n",
    "    for sentence in summary:\n",
    "        results.append(str(sentence))\n",
    "    return results\n",
    "\n",
    "def KLSummary(document, sentences):\n",
    "    parser = PlaintextParser.from_string(document,Tokenizer(\"english\"))\n",
    "    summarizer = KLSummarizer()\n",
    "    summary = summarizer(parser.document, sentences)\n",
    "    results = []\n",
    "    for sentence in summary:\n",
    "        results.append(str(sentence))\n",
    "    return results\n",
    "\n",
    "def ReductionSummary(document, sentences):\n",
    "    parser = PlaintextParser.from_string(document,Tokenizer(\"english\"))\n",
    "    summarizer = ReductionSummarizer()\n",
    "    summary = summarizer(parser.document, sentences)\n",
    "    results = []\n",
    "    for sentence in summary:\n",
    "        results.append(str(sentence))\n",
    "    return results"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O8rijKpln6QW",
    "colab_type": "code",
    "outputId": "a60cf86e-7e29-45e5-fb52-c0d695351e4f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 688
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# run these functions for every possible train/test 10q\n",
    "\n",
    "print('LexRank')\n",
    "summarize_company_docs('ADI', LexRankSummary, 'Lexrank')\n",
    "print('\\n')\n",
    "print('Luhn')\n",
    "summarize_company_docs('ADI', LuhnSummary, 'Luhn')\n",
    "print('\\n')\n",
    "print('LSA')\n",
    "summarize_company_docs('ADI', LsaSummary, 'LSA')\n",
    "print('\\n')\n",
    "print('TextRank')\n",
    "summarize_company_docs('ADI', TextRankSummary, 'TextRank(using sumy)')\n",
    "print('\\n')\n",
    "print('SumBasic')\n",
    "summarize_company_docs('ADI', SumBasicSummary, 'SumBasic')\n",
    "print('\\n')\n",
    "print('KL')\n",
    "summarize_company_docs('ADI', KLSummary, 'KL')\n",
    "print('\\n')\n",
    "print('Reduction')\n",
    "summarize_company_docs('ADI', ReductionSummary, 'Reduction')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "LexRank\n",
      "processed ADI_0000006281_20180505\n",
      "processed ADI_0000006281_20180804\n",
      "processed ADI_0000006281_20190202\n",
      "processed ADI_0000006281_20190504\n",
      "processed ADI_0000006281_20190803\n",
      "\n",
      "\n",
      "Luhn\n",
      "processed ADI_0000006281_20180505\n",
      "processed ADI_0000006281_20180804\n",
      "processed ADI_0000006281_20190202\n",
      "processed ADI_0000006281_20190504\n",
      "processed ADI_0000006281_20190803\n",
      "\n",
      "\n",
      "LSA\n",
      "processed ADI_0000006281_20180505\n",
      "processed ADI_0000006281_20180804\n",
      "processed ADI_0000006281_20190202\n",
      "processed ADI_0000006281_20190504\n",
      "processed ADI_0000006281_20190803\n",
      "\n",
      "\n",
      "TextRank\n",
      "processed ADI_0000006281_20180505\n",
      "processed ADI_0000006281_20180804\n",
      "processed ADI_0000006281_20190202\n",
      "processed ADI_0000006281_20190504\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qI4buR-ho8AX",
    "colab_type": "code",
    "outputId": "facade67-9470-45f6-c5c0-24b6639bae52",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}